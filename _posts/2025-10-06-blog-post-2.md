---
title: 'Who Wants AI in Schools?'
date: 2025-10-16
permalink: /posts/2025/10/blog-post-2/
tags:
  - labor
  - ai
---

The question of AI in schools has been on many teachers’, and likely even more school administrators’, minds. This could manifest as worries of reduction in teacher pay or number of teaching positions, student overreliance on AI, or more general concerns over excessive water and electrical use by AI. Not to mention larger scale misfires like Ed, the [chatbot brought in by the Los Angeles Unified School District](https://calmatters.org/economy/technology/2024/08/botched-ai-education-deals-lessons/) for almost $3 million, which was shelved 3 months later when the startup went belly up. During the short term it was functioning, the chatbot likely violated student data privacy rules[^1]. Other teachers see opportunities in educational AI tools, from saving time planning to aiding in differentiation of instructional materials. However, in my experience, this enthusiasm comes more often from school administrators, people in the educational technology industry, and people not working in education at all. 

I saw these tensions foregrounded this past March, at a one-day conference my school attends every year. An afternoon panel made up entirely of finance industry higher-ups promised to discuss the benefits of AI for neurodiversity. One speaker explained how an AI chatbot could provide a social outlet for children who struggled to connect in the real world. He had seen ChatGPT act as an affirmative, positive companion to his autistic child. Another panelist spoke about how he had used ChatGPT during a crisis moment with his child who was having a tantrum, throwing things at a wall. He consulted the chatbot to generate some potential steps he could respond to the situation with. Teachers could also use these chatbots, a panelist explained, to assist with planning, helping to generate ideas for targeting material to neurodiverse learners.

The panel was met with some fairly critical questions from teachers in the audience, regarding fear of job replacement, inaccurate information, and data center energy use. There were apparently even some jeers and thumbs downs (although I didn’t see them myself). The staff of my school were later chastised by the administrative team for our reaction to the panel, potentially jeopardizing donor relationships. 

If indeed people were heckling panelists, I do think there are more respectful and productive ways of responding to a panel like this in a professional setting. However, I think there was also some justification for these reactions. In many sectors, including education, there has been a push to use AI wherever feasible, without much thought given to the possible outcomes. Many of these calls come from people without training or experience in K-12 education. Or, in this case, the knowledge of psychology and autism to realize that encouraging a child on the spectrum to form a friendship (and the level of trust that implies) with a chatbot is potentially very dangerous. Chatbots, with their tendency to affirm any statements received, can in some cases end up [encouraging self-harm or other unwanted behaviors](https://med.stanford.edu/news/insights/2025/08/ai-chatbots-kids-teens-artificial-intelligence.html). Issues could also occur with using chatbots in crisis situations, as they are obviously not trained in proper protocols for different psychological conditions. 

It is not surprising we hear so many calls for new uses of AI from the finance world. NVIDIA’s[^2] total current valuation has grown to almost 8% of the total value of the S&P 500[^3], and U.S. private AI investment reached $109.1 billion in 2024[^4]. With the massive levels of investment in AI, there are strong financial incentives to continue to increase the use of AI by finding more use cases for the technology. 

Another speaker at the conference highlighted a “special intelligence unit from a country in the Middle East that used the unique skills of autistic people for data analysis” as a positive example of neurodiversity in the workplace. He was referring to the IDF’s Unit 8200, a controversial and covert surveillance and signal intelligence unit. But that’s a discussion for another time.  

This school year, I am already noticing a greater presence of AI in our professional development. An acronym introduced during one training session was apparently generated by AI. Supervisors have suggested to colleagues that they use ChatGPT to help fill in our three yearly personal development goals. As another colleague said, if these three goals are too much work to be filled out manually by genuinely reflecting on our professional aims, why would the solution to this not be to write *fewer* goals every year? Is quantity more important than quality in this case? Is the self-reflection that comes from generating goals not a significant part of the exercise? Given these suggestions, I can’t help but wonder what aspects of our supervision and professional development are being assisted by ChatGPT. Chatbots as they are used here feel almost like paperwork machines, helping us accomplish our professional development in terms of textual production, but perhaps helping less in other ways. 

There are surely productive ways for teachers and school administrators to use AI, but we need to carefully consider who proposals for its use come from, and why. And we cannot forget the fact that these are systems that schools and educators have very little control over, that are often designed without the educational implications fully examined. If school administrators are wondering, what would probably be *most* helpful for teachers is more planning time, less micromanagement, and more democratic control over the conditions of their work. 

[^1]: - <https://www.edsurge.com/news/2024-07-15-an-education-chatbot-company-collapsed-where-did-the-student-data-go>
[^2]: - One of the largest chipmakers in the world, which makes the chips used in most AI data centers
[^3]: - [NVIDIA](https://companiesmarketcap.com/nvidia/marketcap/) - $4.43T as of 10/13/25, [S&P 500 market cap](https://ycharts.com/indicators/sp_500_market_cap#:~:text=Basic%20Info,17.14%25%20from%20one%20year%20ago.) - $57.05T -> 4.43/57.05 = 0.078
[^4]: - <https://hai.stanford.edu/ai-index/2025-ai-index-report/economy>


